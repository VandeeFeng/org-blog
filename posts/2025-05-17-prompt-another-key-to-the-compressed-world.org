#+title: Prompt: Another Key to the Compressed World
#+date: <2025-05-17 11:28>
#+description: 这意味着我不再需要在我的记忆里储存那些大量的信息，只需要建立目录和索引，LLM 会帮助我通过这些索引找到它们之间的联系。当然前提是需要对这些概念有理解，也需要自己甄别 LLM 的幻觉。这也是近两年我一直在做的事情，把信息、知识压缩成一系列的关键字和索引。各种 PKM 就是我想接入 LLM 的数据。LLM 是数据的压缩，它就是一个巨大的 ZIP，prompt 就是解压的钥匙了。在一个模型的基础上根据自己的数据和语料训练出一个自己的大语言模型，我觉得在未来会像每个人有电脑一样普遍。每个人都会有自己的去中心化知识库。
#+filetags: Ramble

* Intro
#+BEGIN_QUOTE
未来能第一个说出来这些「Magic Words」的人，就率先打开了一个新的参数空间。

via: https://x.com/lijigang_com/status/1921103439813283862

#+END_QUOTE

如果说在互联网时代，能够打开浏览器，在搜索框里进行搜索已经是一个必备的技能，那么 AI 时代，会用 prompt 获取到自己需要的内容也是一样。

LLM 迭代很快，但不管技术怎么迭代，prompt 作为输入的窗口是不会消失的。

对于普通人来说，我觉得 prompt 是最直接，也最容易上手的了。

Prompt [[https://zh.wikipedia.org/wiki/%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B][提示工程]] ,简单来说就是我们和 LLM 交互的时候输入的 input，LLM 的回答就是 output。

LLM 是一个概率计算器，它需要通过输入来计算出可能性最大的输出。对不同模型的底层原理越是了解，就越能通过 prompt 发挥出模型的效果。但对于普通人来说，这个学习成本太大了。

而且随着 LLM 的迭代，大模型的能力会越来越强，它对于自然语言的理解会更好，prompt 也可以写的越来越简洁，不必须非要掌握那些特定的格式和技巧。

Chain of Thought (CoT) (思维链提示)，Tree of Thoughts (ToT) (思维树提示)，ReAct (Reason & Act) (推理与行动提示)等等这些在推理模型出现之后，都不是那么必须了。现在 Role prompting (角色提示) 是我用的最多，效果最好的，也最简单。如果不是特定需求下，prompt 写的太复杂，反而会影响 LLM 的输出。

因此，我觉得未来 prompt 的重心会随着 LLM 能力的提升进一步向思维和表达偏移。

* Keyword 关键字

AI 善于回答问题，但不善于提出问题。如何提出更好的问题，才使用 AI 工具的关键。

拿李继刚的这个 prompt 举例：

#+BEGIN_QUOTE

P(x,t) | W(x) ^ L(x)

- W(x): 这个世界是「网状」的，要观察 x 事件，是否陷入了单点思考或线性思考，有没有考虑周边关联结点的影响

- L(x): 这个世界是「立体」的，要观察 x 事件，当前的描述是在哪个层次上，再上一层（更抽象）是什么，再下一层（更具体）是什么？

- P(x): 这个世界是「概率」的，量子世界的测不准原理一直存在着，x 事件成立的概率是多少？对言之凿凿要抱有极大的警惕心，量子不同意。

- P(t): 这个世界是「动态」的。x 事件的描述，过去成立，现在还成立吗？未来还成立吗？充分条件发生变化了吗？这个世界一直在变，x 事件为什么会不变？

vai: https://x.com/lijigang_com/status/1923407635245854964

#+END_QUOTE


LLM 就是一个概率计算器，我一直以来的用法也就是：让 LLM 放大我的思维。

当我们在思考过程中那个小灯泡亮起来的时候，也就是大脑的神经突触连接了，LLM 的底层原理也是模拟大脑。

当我在想一系列的概念、问题的时候，LLM 可以帮助我快速的计算出各种概率，找到它们直接的联系，发散，增加我的想象力。

这意味着我不再需要在我的记忆里储存那些大量的信息，只需要建立目录和索引，LLM 会帮助我通过这些索引找到它们之间的联系。当然前提是需要对这些概念有理解，也需要自己甄别 LLM 的幻觉。

这也是近两年我一直在做的事情，把信息、知识压缩成一系列的关键字和索引。各种 PKM 就是我想接入 LLM 的数据。

LLM 是数据的压缩，它就是一个巨大的 ZIP，prompt 就是解压的钥匙了。

在一个模型的基础上根据自己的数据和语料训练出一个自己的大语言模型，我觉得在未来会像每个人有电脑一样普遍。每个人都会有自己的去中心化知识库。

我最近在折腾树莓派，闲鱼上一个也就 500。接入我的 PKM 数据库，连上 LLM，一个简易的个人小助手 JARVIS 就搞定了。视觉识别，语音对话都很好实现。

* 小结

每一次新的技术出现一定会让我们变懒，这也是技术的初衷，让生活变得便利。

变懒可以，但变笨不行。

LLM 只是一个工具，指望它能让自己干出什么原本就不可能的事情是不现实的，它能做的只是在原有的基础上放大这个概率。

当这些概率都发生变化的时候，或许就会有神奇的事情发生呢？
